{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/frankzl/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/frankzl/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/frankzl/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/frankzl/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../data\", one_hot=True) # y labels are oh-encoded\n",
    "\n",
    "n_train = mnist.train.num_examples # 55,000\n",
    "n_validation = mnist.validation.num_examples # 5000\n",
    "n_test = mnist.test.num_examples # 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784   # input layer (28x28 pixels)\n",
    "n_hidden1 = 512 # 1st hidden layer\n",
    "# n_hidden1 = 1024 # 1st hidden layer\n",
    "n_hidden2 = 256 # 2nd hidden layer\n",
    "# n_hidden3 = 128 # 3rd hidden layer\n",
    "n_hidden3 = 256 # 3rd hidden layer\n",
    "n_output = 10   # output layer (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "n_iterations = 3000\n",
    "batch_size = 128\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_output])\n",
    "keep_prob = tf.placeholder(tf.float32) \n",
    "\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.truncated_normal([n_input, n_hidden1], stddev=0.1)),\n",
    "    'w2': tf.Variable(tf.truncated_normal([n_hidden1, n_hidden2], stddev=0.1)),\n",
    "    'w3': tf.Variable(tf.truncated_normal([n_hidden2, n_hidden3], stddev=0.1)),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden3, n_output], stddev=0.1)),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden1])),\n",
    "    'b2': tf.Variable(tf.constant(0.1, shape=[n_hidden2])),\n",
    "    'b3': tf.Variable(tf.constant(0.1, shape=[n_hidden3])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_output]))\n",
    "}\n",
    "\n",
    "layer_1 = tf.nn.relu(tf.add(tf.matmul(X, weights['w1']), biases['b1']))\n",
    "layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, weights['w2']), biases['b2']))\n",
    "layer_3 = tf.nn.relu(tf.add(tf.matmul(layer_2, weights['w3']), biases['b3']))\n",
    "layer_drop = tf.nn.dropout(layer_3, keep_prob)\n",
    "output_layer = tf.matmul(layer_3, weights['out']) + biases['out']\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=output_layer))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t| Loss = 3.5735555 \t| Accuracy = 0.1640625\n",
      "Iteration 100 \t| Loss = 0.45606515 \t| Accuracy = 0.8515625\n",
      "Iteration 200 \t| Loss = 0.22800857 \t| Accuracy = 0.90625\n",
      "Iteration 300 \t| Loss = 0.15223645 \t| Accuracy = 0.9609375\n",
      "Iteration 400 \t| Loss = 0.19827986 \t| Accuracy = 0.9453125\n",
      "Iteration 500 \t| Loss = 0.13770787 \t| Accuracy = 0.953125\n",
      "Iteration 600 \t| Loss = 0.19680887 \t| Accuracy = 0.9609375\n",
      "Iteration 700 \t| Loss = 0.1900438 \t| Accuracy = 0.9453125\n",
      "Iteration 800 \t| Loss = 0.17051688 \t| Accuracy = 0.96875\n",
      "Iteration 900 \t| Loss = 0.13420914 \t| Accuracy = 0.9609375\n",
      "Iteration 1000 \t| Loss = 0.14227626 \t| Accuracy = 0.953125\n",
      "Iteration 1100 \t| Loss = 0.11655401 \t| Accuracy = 0.9765625\n",
      "Iteration 1200 \t| Loss = 0.060562048 \t| Accuracy = 0.9765625\n",
      "Iteration 1300 \t| Loss = 0.079582654 \t| Accuracy = 0.9765625\n",
      "Iteration 1400 \t| Loss = 0.07649855 \t| Accuracy = 0.984375\n",
      "Iteration 1500 \t| Loss = 0.08564558 \t| Accuracy = 0.96875\n",
      "Iteration 1600 \t| Loss = 0.08966929 \t| Accuracy = 0.984375\n",
      "Iteration 1700 \t| Loss = 0.06468672 \t| Accuracy = 0.984375\n",
      "Iteration 1800 \t| Loss = 0.022424782 \t| Accuracy = 1.0\n",
      "Iteration 1900 \t| Loss = 0.085927315 \t| Accuracy = 0.9765625\n",
      "Iteration 2000 \t| Loss = 0.06025961 \t| Accuracy = 0.9921875\n",
      "Iteration 2100 \t| Loss = 0.05903897 \t| Accuracy = 0.9765625\n",
      "Iteration 2200 \t| Loss = 0.05426301 \t| Accuracy = 0.984375\n",
      "Iteration 2300 \t| Loss = 0.054801673 \t| Accuracy = 0.984375\n",
      "Iteration 2400 \t| Loss = 0.07828813 \t| Accuracy = 0.9765625\n",
      "Iteration 2500 \t| Loss = 0.019494895 \t| Accuracy = 1.0\n",
      "Iteration 2600 \t| Loss = 0.031167042 \t| Accuracy = 0.9921875\n",
      "Iteration 2700 \t| Loss = 0.033420544 \t| Accuracy = 0.9921875\n",
      "Iteration 2800 \t| Loss = 0.042322382 \t| Accuracy = 1.0\n",
      "Iteration 2900 \t| Loss = 0.021627981 \t| Accuracy = 1.0\n",
      "Iteration 3000 \t| Loss = 0.03730409 \t| Accuracy = 0.9921875\n",
      "Iteration 3100 \t| Loss = 0.022947889 \t| Accuracy = 1.0\n",
      "Iteration 3200 \t| Loss = 0.046169385 \t| Accuracy = 0.984375\n",
      "Iteration 3300 \t| Loss = 0.005298592 \t| Accuracy = 1.0\n",
      "Iteration 3400 \t| Loss = 0.018325374 \t| Accuracy = 1.0\n",
      "Iteration 3500 \t| Loss = 0.013212128 \t| Accuracy = 1.0\n",
      "Iteration 3600 \t| Loss = 0.011085654 \t| Accuracy = 1.0\n",
      "Iteration 3700 \t| Loss = 0.009492815 \t| Accuracy = 1.0\n",
      "Iteration 3800 \t| Loss = 0.0320751 \t| Accuracy = 0.9921875\n",
      "Iteration 3900 \t| Loss = 0.013967033 \t| Accuracy = 1.0\n",
      "\n",
      "Accuracy on test set: 0.9754\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    # train on mini batches\n",
    "    for i in range(n_iterations):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step, feed_dict={X: batch_x, Y: batch_y, keep_prob:dropout})\n",
    "    \n",
    "        # print loss and accuracy (per minibatch)\n",
    "        if i%100==0:\n",
    "            minibatch_loss, minibatch_accuracy = sess.run([cross_entropy, accuracy], feed_dict={X: batch_x, Y: batch_y, keep_prob:1.0})\n",
    "            print(\"Iteration\", str(i), \"\\t| Loss =\", str(minibatch_loss), \"\\t| Accuracy =\", str(minibatch_accuracy))\n",
    "            \n",
    "    test_accuracy = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob:1.0})\n",
    "    \n",
    "    final_weights = {\n",
    "        'w1': sess.run( weights['w1'] ),\n",
    "        'w2': sess.run( weights['w2'] ),\n",
    "        'w3': sess.run( weights['w3'] ),\n",
    "        'out': sess.run( weights['out'] )\n",
    "    }\n",
    "    \n",
    "    print(\"\\nAccuracy on test set:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.reshape(final_weights['w3'][3], (16, -1))\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imgplot = plt.imshow(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1024)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weights['w1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
